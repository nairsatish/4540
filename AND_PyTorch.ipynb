{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nairsatish/4540/blob/master/AND_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwgeRHVBB0gy"
      },
      "source": [
        "https://brilliant.org/wiki/backpropagation/\n",
        "\n",
        "Absolutely simplest back propagation example (version 2) https://www.youtube.com/watch?v=8d6jf7s6_Qs\n",
        "\n",
        "A worked example with more neurons - https://www.youtube.com/watch?v=n2L1J5JYgUk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvV5yiNUbCzm"
      },
      "source": [
        "EXAMPLE OF AN AND NETWORK - 2 inputs in layer 1 and 1 neuron in the output layer\n",
        "See \"Helpful Tips\" at the end of the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NziucDl6yuoW",
        "outputId": "9229a1b8-5e6e-47e2-8d4e-21b84aef3077"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f019cc77710>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgYNy37VIn00"
      },
      "source": [
        "DATA (input and output for this supervised learning problem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rXjDBsiOy8lV"
      },
      "outputs": [],
      "source": [
        "X = torch.Tensor([[0,0],[0,1], [1,0], [1,1]])\n",
        "Y = torch.Tensor([0,0,0,1]).view(-1,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uuARj4AyHot"
      },
      "source": [
        "HYPOTHESIS/MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qwl3sHRnzDQQ"
      },
      "outputs": [],
      "source": [
        "class AND(nn.Module):\n",
        "    def __init__(self, input_dim = 2, output_dim=1):\n",
        "        # Initialize attributes and methods of the parent class nn.Module\n",
        "        super(AND, self).__init__()\n",
        "        \n",
        "        # Initialize layers\n",
        "        self.lin1 = nn.Linear(input_dim, output_dim)\n",
        "        #self.lin2 = nn.Linear(2, output_dim)\n",
        "    \n",
        "    # Each custom torch class (inherited from nn.Module) has to have a forward() method\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        #x = self.lin2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IXcZnxYRzJ58"
      },
      "outputs": [],
      "source": [
        "model = AND()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIgvHHsszLo1",
        "outputId": "fdad0b77-7ac7-44a2-e3e1-64e88715b745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AND(\n",
            "  (lin1): Linear(in_features=2, out_features=1, bias=True)\n",
            "), Linear(in_features=2, out_features=1, bias=True)]\n"
          ]
        }
      ],
      "source": [
        "def weights_init(model):\n",
        "    print(list(model.modules())) # network from above printed out\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            # initialize the weight tensor, here we use a normal distribution\n",
        "            m.weight.data.normal_(0, 1)\n",
        "            m.bias.data.normal_(0, 1)\n",
        "\n",
        "weights_init(model) # may not be needed but used to show the idea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkeust3zyYwU"
      },
      "source": [
        "COST or LOSS FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yqkxJx0CzPce"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOl_E8OmycFd"
      },
      "source": [
        "UPDATE RULE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zC-ffgFPzTb5"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.0) # Another popular optimizer is ADAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAX8FpUMyg1-"
      },
      "source": [
        "SETTING IT ALL UP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB8zkbQEzXyo",
        "outputId": "d6765122-4b6d-417d-c197-eeb77b4d9bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial lin1.weight: Parameter containing:\n",
            "tensor([[ 0.6985, -2.3659]], requires_grad=True)\n",
            "initial lin1.bias: Parameter containing:\n",
            "tensor([0.1122], requires_grad=True)\n",
            "--------------------\n",
            "\n",
            "\n",
            "First epoch gradients:\n",
            "--------------------\n",
            "\n",
            ">> Step 0:\n",
            "Data_point -- X: tensor([0., 1.]), y: tensor([0.]):\n",
            "grad(lin1.weight): tensor([[0.0000, 0.0163]])\n",
            "grad(lin1.bias): tensor([0.0163])\n",
            "lin1.weight: Parameter containing:\n",
            "tensor([[ 0.6985, -2.3662]], requires_grad=True)\n",
            "lin1.bias: Parameter containing:\n",
            "tensor([0.1119], requires_grad=True)\n",
            "\n",
            "\n",
            ">> Step 1:\n",
            "Data_point -- X: tensor([0., 0.]), y: tensor([0.]):\n",
            "grad(lin1.weight): tensor([[0., 0.]])\n",
            "grad(lin1.bias): tensor([0.2631])\n",
            "lin1.weight: Parameter containing:\n",
            "tensor([[ 0.6985, -2.3662]], requires_grad=True)\n",
            "lin1.bias: Parameter containing:\n",
            "tensor([0.1066], requires_grad=True)\n",
            "\n",
            "\n",
            ">> Step 2:\n",
            "Data_point -- X: tensor([1., 0.]), y: tensor([0.]):\n",
            "grad(lin1.weight): tensor([[0.2951, 0.0000]])\n",
            "grad(lin1.bias): tensor([0.2951])\n",
            "lin1.weight: Parameter containing:\n",
            "tensor([[ 0.6926, -2.3662]], requires_grad=True)\n",
            "lin1.bias: Parameter containing:\n",
            "tensor([0.1007], requires_grad=True)\n",
            "\n",
            "\n",
            ">> Step 3:\n",
            "Data_point -- X: tensor([0., 1.]), y: tensor([0.]):\n",
            "grad(lin1.weight): tensor([[0.0000, 0.0160]])\n",
            "grad(lin1.bias): tensor([0.0160])\n",
            "lin1.weight: Parameter containing:\n",
            "tensor([[ 0.6926, -2.3665]], requires_grad=True)\n",
            "lin1.bias: Parameter containing:\n",
            "tensor([0.1004], requires_grad=True)\n",
            "\n",
            "\n",
            "\n",
            "Loss History:\n",
            "--------------------\n",
            "Epoch: 0, Loss: 0.008840113878250122, \n",
            "Epoch: 500, Loss: 0.08310043066740036, \n",
            "Epoch: 1000, Loss: 0.14177052676677704, \n",
            "Epoch: 1500, Loss: 0.0779089406132698, \n",
            "Epoch: 2000, Loss: 0.0014984143199399114, \n"
          ]
        }
      ],
      "source": [
        "#print initial weights before start of training\n",
        "print(f\"initial lin1.weight: {model.lin1.weight}\")\n",
        "print(f\"initial lin1.bias: {model.lin1.bias}\")\n",
        "print(\"--------------------\")\n",
        "print(\"\\n\")\n",
        "\n",
        "epochs = 2001\n",
        "steps = X.size(0)\n",
        "for i in range(epochs):\n",
        "    \n",
        "    for j in range(steps):\n",
        "        data_point = np.random.randint(X.size(0))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        y_hat = model(X[data_point])\n",
        "        loss = loss_func.forward(y_hat, Y[data_point]) # loss_func(y_hat, Y[data_point]) also works\n",
        "        \n",
        "        loss.backward() \n",
        "        optimizer.step()\n",
        "\n",
        "        if i == 0:\n",
        "            if j == 0:\n",
        "                print(\"First epoch gradients:\\n--------------------\\n\")\n",
        "            print(f\">> Step {j}:\")\n",
        "            print(f\"Data_point -- X: {X[data_point]}, y: {Y[data_point]}:\")\n",
        "            print(f\"grad(lin1.weight): {model.lin1.weight.grad}\")\n",
        "            print(f\"grad(lin1.bias): {model.lin1.bias.grad}\")\n",
        "            # these gradients are used to calculate the updated weights and bias\n",
        "            print(f\"lin1.weight: {model.lin1.weight}\")\n",
        "            print(f\"lin1.bias: {model.lin1.bias}\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "            if j == steps - 1:\n",
        "                print(\"\\nLoss History:\")\n",
        "                print(\"--------------------\")\n",
        "        \n",
        "    if i % 500 == 0:\n",
        "         print(\"Epoch: {0}, Loss: {1}, \".format(i, loss.data.numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auCBHzWf136b",
        "outputId": "2f198493-0dc6-41db-db45-3efe911068aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('lin1.weight', Parameter containing:\n",
            "tensor([[2.0903, 2.0440]], requires_grad=True)), ('lin1.bias', Parameter containing:\n",
            "tensor([-3.2123], requires_grad=True))]\n"
          ]
        }
      ],
      "source": [
        "model_params = list(model.named_parameters())\n",
        "print(model_params)\n",
        "model_params = list(model.parameters()) # used to make below cell better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJxeG6aKy2Gc"
      },
      "source": [
        "USING THE INFO ABOVE, CAN YOU GET THE EQUATIONS OF THE LINES PLOTTED BELOW?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "hdUTc_ji18WA",
        "outputId": "ba89c584-a014-435d-96a5-6f6686c15dbc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "model_weights = model_params[0].data.numpy()\n",
        "model_bias = model_params[1].data.numpy()\n",
        "\n",
        "plt.scatter(X.numpy()[3, 0], X.numpy()[3, 1], s=50)\n",
        "plt.scatter(X.numpy()[[0, 1,2], 0], X.numpy()[[0, 1, 2], 1], c='red', s=50)\n",
        "\n",
        "# weights(0,0) and (0,1) are from in the (TO,FROM) format, \n",
        "# i.e., to neuron 0(or 1) from input 0(or 1). See Helpful Hints at the end\n",
        "x_1 = np.arange(-0.1, 1.1, 0.1)\n",
        "y_1 = ((x_1 * model_weights[0,0]) + model_bias[0]) / (-model_weights[0,1])\n",
        "plt.plot(x_1, y_1)\n",
        "\n",
        "plt.legend([\"neuron_1\", \"neuron_2\"], loc=8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSvsUe1Ka5t9"
      },
      "source": [
        "EXERCISES - (i) Find the equation for the separation line in the plot using the weights and biases and confirm that it is correct. (ii) Confirm that the derivative of the loss function with respect to the two weights and bias are correct after one step of the iteration process. (iii) Note that the derivates are calculated by passing the error thought the nonlinearity. Now you are to compute the derivative itself by hand after the first iteration and confirm that it matches what PyTorch has provided.\n",
        "__________________\n",
        "ADDITIONAL EXERCISES: (i) Now try to use momentum=0.9 instead of 0 that we have presently, to study how that hyperparameter works; (ii) extend this code to solve the XOR problem\n",
        "\n",
        "Documentation - pytorch.org\n",
        "\n",
        "HELPFUL TIPS\n",
        "\n",
        "\n",
        "```\n",
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(x[1][2])\n",
        ">>> tensor(6)\n",
        "```\n",
        "\n",
        "```\n",
        "x[0][1] = 8\n",
        "print(x)\n",
        ">>> tensor([[ 1,  8,  3],\n",
        "            [ 4,  5,  6]])\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}