{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nairsatish/4540/blob/master/CNNMNIST_BinaryClassif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7501f5d9",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7501f5d9",
        "outputId": "eaccf287-4a72-4f08-87b0-ed69f1b28763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'torch,'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if RunningInCOLAB:\n",
        "    !pip install torch, torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "436b45d6",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "436b45d6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa108e06",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "aa108e06"
      },
      "source": [
        "## CNN Details\n",
        "\n",
        "The kernel/filter/weight matrix is a 5x5 matrix. Out channels corresponds to the number of created feature maps, and therefore impacts the number of kernels.\n",
        "\n",
        "MaxPool2D is a 2x2 sliding window taking the maximum value in that window.\n",
        "\n",
        "Since this is the MNIST dataset, each image is 28x28. If we take a batch size of 1, this means our structure is:\n",
        "\n",
        "Input (28x28) **->**\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv2D (16x28x28) **->** ReLU (16x28x28) **->** MaxPool2D (16x14x14) **->**\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Conv2D (32x14x14) **->** RelU (32x14x14) **->** MaxPool2D (32x7x7) **->**\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Flatten (1568x1) **->** FCN **->**\n",
        "Returned Output (10x1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f7ee432c-e3cb-4b41-9d2e-126c475ae261",
      "metadata": {
        "id": "f7ee432c-e3cb-4b41-9d2e-126c475ae261"
      },
      "outputs": [],
      "source": [
        "#Derived from https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118\n",
        "\n",
        "class ExampleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExampleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(5,5), stride=(1,1), padding=2)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.pool2d = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(5,5), stride=(1,1), padding=2)\n",
        "        self.fcn = nn.Linear(32 * 7 * 7, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool2d(self.activation(self.conv1(x)))\n",
        "        x = self.pool2d(self.activation(self.conv2(x)))\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        out = self.fcn(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9fe06a3b-9d23-4a53-99f5-6ac33d827146",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fe06a3b-9d23-4a53-99f5-6ac33d827146",
        "outputId": "9875fbe5-3b69-4545-98d3-79250838a272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 79310570.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 9854038.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 27659140.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3529836.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\"\"\"\n",
        "Running in COLAB assumes you've not imported the entire repository and simply saves the data with the notebook\n",
        "\n",
        "Running in Jupyter Notebook assumes you have imported the entire repository and stores it in the data folder\n",
        "\"\"\"\n",
        "if RunningInCOLAB:\n",
        "    train_data = torchvision.datasets.MNIST('.', train=True, transform=ToTensor(), download=True)\n",
        "    test_data = torchvision.datasets.MNIST('.', train=False, transform=ToTensor(), download=True)\n",
        "else:\n",
        "    train_data = torchvision.datasets.MNIST('.', train=True, transform=ToTensor(), download=True)\n",
        "    test_data = torchvision.datasets.MNIST('.', train=False, transform=ToTensor(), download=True)\n",
        "batch_size = 124\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "loaders = {'train' : train_loader, 'test' : test_loader}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "987507e2-89bd-4a7f-81d5-916745046a61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "987507e2-89bd-4a7f-81d5-916745046a61",
        "outputId": "7c11b19f-67e1-4882-efb6-c5d1ce100277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/484], Loss: 0.1933\n",
            "Epoch [1/10], Step [200/484], Loss: 0.0376\n",
            "Epoch [1/10], Step [300/484], Loss: 0.0622\n",
            "Epoch [1/10], Step [400/484], Loss: 0.1148\n",
            "Epoch [2/10], Step [100/484], Loss: 0.0352\n",
            "Epoch [2/10], Step [200/484], Loss: 0.0396\n",
            "Epoch [2/10], Step [300/484], Loss: 0.0150\n",
            "Epoch [2/10], Step [400/484], Loss: 0.0337\n",
            "Epoch [3/10], Step [100/484], Loss: 0.0161\n",
            "Epoch [3/10], Step [200/484], Loss: 0.0279\n",
            "Epoch [3/10], Step [300/484], Loss: 0.0197\n",
            "Epoch [3/10], Step [400/484], Loss: 0.0552\n",
            "Epoch [4/10], Step [100/484], Loss: 0.0335\n",
            "Epoch [4/10], Step [200/484], Loss: 0.0593\n",
            "Epoch [4/10], Step [300/484], Loss: 0.0124\n",
            "Epoch [4/10], Step [400/484], Loss: 0.0491\n",
            "Epoch [5/10], Step [100/484], Loss: 0.0211\n",
            "Epoch [5/10], Step [200/484], Loss: 0.0263\n",
            "Epoch [5/10], Step [300/484], Loss: 0.0324\n",
            "Epoch [5/10], Step [400/484], Loss: 0.0452\n",
            "Epoch [6/10], Step [100/484], Loss: 0.0877\n",
            "Epoch [6/10], Step [200/484], Loss: 0.0525\n",
            "Epoch [6/10], Step [300/484], Loss: 0.0360\n",
            "Epoch [6/10], Step [400/484], Loss: 0.0384\n",
            "Epoch [7/10], Step [100/484], Loss: 0.0407\n",
            "Epoch [7/10], Step [200/484], Loss: 0.0349\n",
            "Epoch [7/10], Step [300/484], Loss: 0.0581\n",
            "Epoch [7/10], Step [400/484], Loss: 0.0369\n",
            "Epoch [8/10], Step [100/484], Loss: 0.0632\n",
            "Epoch [8/10], Step [200/484], Loss: 0.0222\n",
            "Epoch [8/10], Step [300/484], Loss: 0.0749\n",
            "Epoch [8/10], Step [400/484], Loss: 0.0044\n",
            "Epoch [9/10], Step [100/484], Loss: 0.0850\n"
          ]
        }
      ],
      "source": [
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "\n",
        "cnn = ExampleCNN()\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()   \n",
        "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)   \n",
        "\n",
        "def train(epochs, network, data_loaders):\n",
        "    \n",
        "    network.train()\n",
        "        \n",
        "    # Train the model\n",
        "    total_step = len(data_loaders['train'])\n",
        "        \n",
        "    for epoch in range(epochs):\n",
        "        for i, (x, y) in enumerate(data_loaders['train']):\n",
        "            \n",
        "            # gives batch data, normalize x when iterate train_loader\n",
        "            b_x = Variable(x)   # batch x\n",
        "            b_y = Variable(y)   # batch y\n",
        "            b_y[b_y <= 4] = 0\n",
        "            b_y[b_y > 4] = 1\n",
        "            output = network(b_x)\n",
        "            loss = loss_func(output, b_y)\n",
        "            \n",
        "            # clear gradients for this training step   \n",
        "            optimizer.zero_grad()           \n",
        "            \n",
        "            # backpropagation, compute gradients \n",
        "            loss.backward()                # apply gradients             \n",
        "            optimizer.step()                \n",
        "            \n",
        "            if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                       .format(epoch + 1, epochs, i + 1, total_step, loss.item()))\n",
        "\n",
        "train(num_epochs, cnn, loaders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac145461-653a-41bb-bebc-2408724640f6",
      "metadata": {
        "id": "ac145461-653a-41bb-bebc-2408724640f6"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "    # Test the model\n",
        "    cnn.eval()    \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for x, y in loaders['test']:\n",
        "            y[y <= 4] = 0\n",
        "            y[y > 4] = 1\n",
        "            out = cnn(x)\n",
        "            y_prediction = torch.max(out, 1)[1].data.squeeze()\n",
        "            accuracy = (y_prediction == y).sum().item() / float(y.size(0))\n",
        "            pass\n",
        "        print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
        "    \n",
        "    pass\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "776d1011-c7ca-4d8e-92dc-393480073f3b",
      "metadata": {
        "id": "776d1011-c7ca-4d8e-92dc-393480073f3b"
      },
      "outputs": [],
      "source": [
        "sample = next(iter(loaders['test']))\n",
        "images, labels = sample\n",
        "actual_number = labels[:10].numpy()\n",
        "actual_number[actual_number <= 4] = 0\n",
        "actual_number[actual_number > 4] = 1\n",
        "test_output = cnn(images[:10])\n",
        "y_predictions = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
        "print(f'Prediction number: {y_predictions}')\n",
        "print(f'Actual number: {actual_number}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b681ed-aa09-49e6-b771-a2ffea08d52b",
      "metadata": {
        "id": "85b681ed-aa09-49e6-b771-a2ffea08d52b"
      },
      "outputs": [],
      "source": [
        "print(cnn.conv1.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93bbc4c-8e07-4e97-a4fc-c53cd2502e97",
      "metadata": {
        "id": "e93bbc4c-8e07-4e97-a4fc-c53cd2502e97"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "layer1_filter = 0\n",
        "\n",
        "plt.imshow(np.squeeze(cnn.conv1.weight.detach().numpy()[layer1_filter,:,:,:]), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a6777dd-6525-49cb-957b-e7f1afb7a6ca",
      "metadata": {
        "id": "4a6777dd-6525-49cb-957b-e7f1afb7a6ca"
      },
      "outputs": [],
      "source": [
        "layer2_filter = 0\n",
        "\n",
        "plt.imshow(cnn.conv2.weight.detach().numpy()[layer2_filter, layer1_filter, :, :], cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be6a3340-7d57-47f4-a191-0c774eb72faa",
      "metadata": {
        "id": "be6a3340-7d57-47f4-a191-0c774eb72faa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f7d366e",
      "metadata": {
        "id": "6f7d366e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}